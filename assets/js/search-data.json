{
  
    
        "post0": {
            "title": "Exploring Titanic Dataset",
            "content": ". The objective of this notebook is to explain each steps and decision we take during solution and development of Titanic Dataset in Kaggle Competitions. . # data analysis import pandas as pd import numpy as np import random as rnd # data visualization import seaborn as sns import matplotlib.pyplot as plt %matplotlib inline # machine learning from sklearn.linear_model import LogisticRegression from sklearn.svm import SVC, LinearSVC from sklearn.ensemble import RandomForestClassifier from sklearn.neighbors import KNeighborsClassifier from sklearn.naive_bayes import GaussianNB from sklearn.linear_model import Perceptron from sklearn.linear_model import SGDClassifier from sklearn.tree import DecisionTreeClassifier . . pd.options.display.max_columns = 100 . . 1.Reading data . The Python Pandas packages helps us work with our datasets. We start by acquiring the training and testing datasets into Pandas DataFrames. We also combine these datasets to run certain operations on both datasets together. . train = pd.read_csv(&#39;train.csv&#39;) test = pd.read_csv(&#39;test.csv&#39;) df = [train, test] . 2.Exploratory Data Analysis . Here we have to analyze and investigate data sets and summarize their main characteristics. . print(train.columns.values) . [&#39;PassengerId&#39; &#39;Survived&#39; &#39;Pclass&#39; &#39;Name&#39; &#39;Sex&#39; &#39;Age&#39; &#39;SibSp&#39; &#39;Parch&#39; &#39;Ticket&#39; &#39;Fare&#39; &#39;Cabin&#39; &#39;Embarked&#39;] . train.dtypes . PassengerId int64 Survived int64 Pclass int64 Name object Sex object Age float64 SibSp int64 Parch int64 Ticket object Fare float64 Cabin object Embarked object dtype: object . We can classify data into : 1.Categorical and Numerical . Categorical: Survived, Sex, and Embarked. Ordinal: Pclass. | Numerical: Age, Fare. Discrete: SibSp, Parch. | . train.head() . PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked . 0 1 | 0 | 3 | Braund, Mr. Owen Harris | male | 22.0 | 1 | 0 | A/5 21171 | 7.2500 | NaN | S | . 1 2 | 1 | 1 | Cumings, Mrs. John Bradley (Florence Briggs Th... | female | 38.0 | 1 | 0 | PC 17599 | 71.2833 | C85 | C | . 2 3 | 1 | 3 | Heikkinen, Miss. Laina | female | 26.0 | 0 | 0 | STON/O2. 3101282 | 7.9250 | NaN | S | . 3 4 | 1 | 1 | Futrelle, Mrs. Jacques Heath (Lily May Peel) | female | 35.0 | 1 | 0 | 113803 | 53.1000 | C123 | S | . 4 5 | 0 | 3 | Allen, Mr. William Henry | male | 35.0 | 0 | 0 | 373450 | 8.0500 | NaN | S | . train.tail() . PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked . 886 887 | 0 | 2 | Montvila, Rev. Juozas | male | 27.0 | 0 | 0 | 211536 | 13.00 | NaN | S | . 887 888 | 1 | 1 | Graham, Miss. Margaret Edith | female | 19.0 | 0 | 0 | 112053 | 30.00 | B42 | S | . 888 889 | 0 | 3 | Johnston, Miss. Catherine Helen &quot;Carrie&quot; | female | NaN | 1 | 2 | W./C. 6607 | 23.45 | NaN | S | . 889 890 | 1 | 1 | Behr, Mr. Karl Howell | male | 26.0 | 0 | 0 | 111369 | 30.00 | C148 | C | . 890 891 | 0 | 3 | Dooley, Mr. Patrick | male | 32.0 | 0 | 0 | 370376 | 7.75 | NaN | Q | . Name contains Titles(eg. Mr,Mrs,Miss etc) | Ticket coloumn contains alphanumeric data. | Cabin is also alphanumeric. | . train.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 891 entries, 0 to 890 Data columns (total 12 columns): # Column Non-Null Count Dtype -- -- 0 PassengerId 891 non-null int64 1 Survived 891 non-null int64 2 Pclass 891 non-null int64 3 Name 891 non-null object 4 Sex 891 non-null object 5 Age 714 non-null float64 6 SibSp 891 non-null int64 7 Parch 891 non-null int64 8 Ticket 891 non-null object 9 Fare 891 non-null float64 10 Cabin 204 non-null object 11 Embarked 889 non-null object dtypes: float64(2), int64(5), object(5) memory usage: 83.7+ KB . test.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 418 entries, 0 to 417 Data columns (total 11 columns): # Column Non-Null Count Dtype -- -- 0 PassengerId 418 non-null int64 1 Pclass 418 non-null int64 2 Name 418 non-null object 3 Sex 418 non-null object 4 Age 332 non-null float64 5 SibSp 418 non-null int64 6 Parch 418 non-null int64 7 Ticket 418 non-null object 8 Fare 417 non-null float64 9 Cabin 91 non-null object 10 Embarked 418 non-null object dtypes: float64(2), int64(4), object(5) memory usage: 36.0+ KB . In training dataset Cabin,Age,Embarked features contain a number of null values. | In testing dataset Cabin,Age contain a number of null values. | . ((train.isnull().sum()/len(train))*100) . PassengerId 0.000000 Survived 0.000000 Pclass 0.000000 Name 0.000000 Sex 0.000000 Age 19.865320 SibSp 0.000000 Parch 0.000000 Ticket 0.000000 Fare 0.000000 Cabin 77.104377 Embarked 0.224467 dtype: float64 . ((test.isnull().sum()/len(test))*100) . PassengerId 0.000000 Pclass 0.000000 Name 0.000000 Sex 0.000000 Age 20.574163 SibSp 0.000000 Parch 0.000000 Ticket 0.000000 Fare 0.239234 Cabin 78.229665 Embarked 0.000000 dtype: float64 . train.describe() . PassengerId Survived Pclass Age SibSp Parch Fare . count 891.000000 | 891.000000 | 891.000000 | 714.000000 | 891.000000 | 891.000000 | 891.000000 | . mean 446.000000 | 0.383838 | 2.308642 | 29.699118 | 0.523008 | 0.381594 | 32.204208 | . std 257.353842 | 0.486592 | 0.836071 | 14.526497 | 1.102743 | 0.806057 | 49.693429 | . min 1.000000 | 0.000000 | 1.000000 | 0.420000 | 0.000000 | 0.000000 | 0.000000 | . 25% 223.500000 | 0.000000 | 2.000000 | 20.125000 | 0.000000 | 0.000000 | 7.910400 | . 50% 446.000000 | 0.000000 | 3.000000 | 28.000000 | 0.000000 | 0.000000 | 14.454200 | . 75% 668.500000 | 1.000000 | 3.000000 | 38.000000 | 1.000000 | 0.000000 | 31.000000 | . max 891.000000 | 1.000000 | 3.000000 | 80.000000 | 8.000000 | 6.000000 | 512.329200 | . test.describe() . PassengerId Pclass Age SibSp Parch Fare . count 418.000000 | 418.000000 | 332.000000 | 418.000000 | 418.000000 | 417.000000 | . mean 1100.500000 | 2.265550 | 30.272590 | 0.447368 | 0.392344 | 35.627188 | . std 120.810458 | 0.841838 | 14.181209 | 0.896760 | 0.981429 | 55.907576 | . min 892.000000 | 1.000000 | 0.170000 | 0.000000 | 0.000000 | 0.000000 | . 25% 996.250000 | 1.000000 | 21.000000 | 0.000000 | 0.000000 | 7.895800 | . 50% 1100.500000 | 3.000000 | 27.000000 | 0.000000 | 0.000000 | 14.454200 | . 75% 1204.750000 | 3.000000 | 39.000000 | 1.000000 | 0.000000 | 31.500000 | . max 1309.000000 | 3.000000 | 76.000000 | 8.000000 | 9.000000 | 512.329200 | . train.describe(include=[&#39;O&#39;]) . Name Sex Ticket Cabin Embarked . count 891 | 891 | 891 | 204 | 889 | . unique 891 | 2 | 681 | 147 | 3 | . top Foreman, Mr. Benjamin Laventall | male | 347082 | B96 B98 | S | . freq 1 | 577 | 7 | 4 | 644 | . test.describe(include=[&#39;O&#39;]) . Name Sex Ticket Cabin Embarked . count 418 | 418 | 418 | 91 | 418 | . unique 418 | 2 | 363 | 76 | 3 | . top Carlsson, Mr. Carl Robert | male | PC 17608 | B57 B59 B63 B66 | S | . freq 1 | 266 | 5 | 3 | 270 | . Names are unique,Total 891 unique names, | 65% of data are male. | Cabin values have several dupicates. Meaning lot of people shared a cabin. | Embarked takes three possible values. | S port used by most passengers. //Southampton | Ticket feature has 22% of duplicate values | . train[[&#39;Pclass&#39;, &#39;Survived&#39;]].groupby([&#39;Pclass&#39;], as_index=False).mean().sort_values(by=&#39;Survived&#39;, ascending=False) . Pclass Survived . 0 1 | 0.629630 | . 1 2 | 0.472826 | . 2 3 | 0.242363 | . train[[&quot;Sex&quot;, &quot;Survived&quot;]].groupby([&#39;Sex&#39;], as_index=False).mean().sort_values(by=&#39;Survived&#39;, ascending=False) . Sex Survived . 0 female | 0.742038 | . 1 male | 0.188908 | . train[[&quot;SibSp&quot;, &quot;Survived&quot;]].groupby([&#39;SibSp&#39;], as_index=False).mean().sort_values(by=&#39;Survived&#39;, ascending=False) . SibSp Survived . 1 1 | 0.535885 | . 2 2 | 0.464286 | . 0 0 | 0.345395 | . 3 3 | 0.250000 | . 4 4 | 0.166667 | . 5 5 | 0.000000 | . 6 8 | 0.000000 | . train[[&quot;Parch&quot;, &quot;Survived&quot;]].groupby([&#39;Parch&#39;], as_index=False).mean().sort_values(by=&#39;Survived&#39;, ascending=False) . Parch Survived . 3 3 | 0.600000 | . 1 1 | 0.550847 | . 2 2 | 0.500000 | . 0 0 | 0.343658 | . 5 5 | 0.200000 | . 4 4 | 0.000000 | . 6 6 | 0.000000 | . Pclass We observe significant correlation (&gt;0.5) among Pclass=1 and Survived. | Sex We confirm the observation during problem definition that Sex=female had very high survival rate at 74%. | SibSp and Parch These features have zero correlation for certain values. | . 3.Data Visualization . Visualization of data can reveal many insights that can help us in determining features in modelling. . sns.set(palette = &quot;flare&quot;) grid = sns.FacetGrid(train, col=&#39;Survived&#39;,height = 10) grid.map(plt.hist, &#39;Age&#39;, bins=20) . &lt;seaborn.axisgrid.FacetGrid at 0x7f4706713280&gt; . Most passengers are in 15-35 age range. | Children aged &lt;=4 had a high survival rate. | Oldest passengers aged above 80 survived. | Large number of 15-25 year olds did not survive. | Age is an important feature. | . grid = sns.FacetGrid(train, col=&#39;Survived&#39;, row=&#39;Pclass&#39;, size=5) grid.map(plt.hist, &#39;Age&#39;, alpha=.5, bins=20) grid.add_legend(); . /home/jithin/.local/lib/python3.8/site-packages/seaborn/axisgrid.py:316: UserWarning: The `size` parameter has been renamed to `height`; please update your code. warnings.warn(msg, UserWarning) . Pclass=3 had most passengers, however most did not survive. | Child passengers in Pclass=2 and Pclass=3 mostly survived. | Most passengers in Pclass=1 survived. | Pclass varies in terms of Age distribution of passengers. | . grid = sns.FacetGrid(train, row=&#39;Embarked&#39;, size=5) grid.map(sns.pointplot, &#39;Pclass&#39;, &#39;Survived&#39;, &#39;Sex&#39;) grid.add_legend() . /home/jithin/.local/lib/python3.8/site-packages/seaborn/axisgrid.py:316: UserWarning: The `size` parameter has been renamed to `height`; please update your code. warnings.warn(msg, UserWarning) /home/jithin/.local/lib/python3.8/site-packages/seaborn/axisgrid.py:643: UserWarning: Using the pointplot function without specifying `order` is likely to produce an incorrect plot. warnings.warn(warning) /home/jithin/.local/lib/python3.8/site-packages/seaborn/axisgrid.py:648: UserWarning: Using the pointplot function without specifying `hue_order` is likely to produce an incorrect plot. warnings.warn(warning) . &lt;seaborn.axisgrid.FacetGrid at 0x7f4703a897f0&gt; . Female passengers had much better survival rate than males. | In Embarked=C where males had higher survival rate. | Males had better survival rate in Pclass=3 when compared with Pclass=2 for C and Q ports. | Ports of embarkation have varying survival rates for Pclass=3 and among male passengers. | . grid = sns.FacetGrid(train, row=&#39;Embarked&#39;, col=&#39;Survived&#39;, size=5) grid.map(sns.barplot, &#39;Sex&#39;, &#39;Fare&#39;, alpha=.5, ci=None) grid.add_legend() . /home/jithin/.local/lib/python3.8/site-packages/seaborn/axisgrid.py:316: UserWarning: The `size` parameter has been renamed to `height`; please update your code. warnings.warn(msg, UserWarning) /home/jithin/.local/lib/python3.8/site-packages/seaborn/axisgrid.py:643: UserWarning: Using the barplot function without specifying `order` is likely to produce an incorrect plot. warnings.warn(warning) . &lt;seaborn.axisgrid.FacetGrid at 0x7f4703a3faf0&gt; . Higher fare paying passengers had better survival. | Port of embarkation correlates with survival rates. | . 4.Feature Engineering . for dataset in df: dataset[&#39;Title&#39;] = dataset.Name.str.extract(&#39; ([A-Za-z]+) .&#39;, expand=False) pd.crosstab(train[&#39;Title&#39;], train[&#39;Sex&#39;]) . Sex female male . Title . Capt 0 | 1 | . Col 0 | 2 | . Countess 1 | 0 | . Don 0 | 1 | . Dr 1 | 6 | . Jonkheer 0 | 1 | . Lady 1 | 0 | . Major 0 | 2 | . Master 0 | 40 | . Miss 182 | 0 | . Mlle 2 | 0 | . Mme 1 | 0 | . Mr 0 | 517 | . Mrs 125 | 0 | . Ms 1 | 0 | . Rev 0 | 6 | . Sir 0 | 1 | . for dataset in df: dataset[&#39;Title&#39;] = dataset[&#39;Title&#39;].replace([&#39;Lady&#39;, &#39;Countess&#39;,&#39;Capt&#39;, &#39;Col&#39;, &#39;Don&#39;, &#39;Dr&#39;, &#39;Major&#39;, &#39;Rev&#39;, &#39;Sir&#39;, &#39;Jonkheer&#39;, &#39;Dona&#39;], &#39;Other&#39;) dataset[&#39;Title&#39;] = dataset[&#39;Title&#39;].replace(&#39;Mlle&#39;, &#39;Miss&#39;) dataset[&#39;Title&#39;] = dataset[&#39;Title&#39;].replace(&#39;Ms&#39;, &#39;Miss&#39;) dataset[&#39;Title&#39;] = dataset[&#39;Title&#39;].replace(&#39;Mme&#39;, &#39;Mrs&#39;) train[[&#39;Title&#39;, &#39;Survived&#39;]].groupby([&#39;Title&#39;], as_index=False).mean() . Title Survived . 0 Master | 0.575000 | . 1 Miss | 0.702703 | . 2 Mr | 0.156673 | . 3 Mrs | 0.793651 | . 4 Other | 0.347826 | . title_mapping = {&quot;Mr&quot;: 1, &quot;Miss&quot;: 2, &quot;Mrs&quot;: 3, &quot;Master&quot;: 4, &quot;Other&quot;: 5} for dataset in df: dataset[&#39;Title&#39;] = dataset[&#39;Title&#39;].map(title_mapping) dataset[&#39;Title&#39;] = dataset[&#39;Title&#39;].fillna(0) train.head() . PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked Title . 0 1 | 0 | 3 | Braund, Mr. Owen Harris | male | 22.0 | 1 | 0 | A/5 21171 | 7.2500 | NaN | S | 1 | . 1 2 | 1 | 1 | Cumings, Mrs. John Bradley (Florence Briggs Th... | female | 38.0 | 1 | 0 | PC 17599 | 71.2833 | C85 | C | 3 | . 2 3 | 1 | 3 | Heikkinen, Miss. Laina | female | 26.0 | 0 | 0 | STON/O2. 3101282 | 7.9250 | NaN | S | 2 | . 3 4 | 1 | 1 | Futrelle, Mrs. Jacques Heath (Lily May Peel) | female | 35.0 | 1 | 0 | 113803 | 53.1000 | C123 | S | 3 | . 4 5 | 0 | 3 | Allen, Mr. William Henry | male | 35.0 | 0 | 0 | 373450 | 8.0500 | NaN | S | 1 | . train = train.drop([&#39;Name&#39;, &#39;PassengerId&#39;], axis=1) test = test.drop([&#39;Name&#39;], axis=1) df = [train, test] train.shape, test.shape #Dropping the Name and PassengerID feature from training and testing datasets . ((891, 11), (418, 11)) . Converting Categorical Features . for dataset in df: dataset[&#39;Sex&#39;] = dataset[&#39;Sex&#39;].map( {&#39;female&#39;: 1, &#39;male&#39;: 0} ).astype(int) train.head() . Survived Pclass Sex Age SibSp Parch Ticket Fare Cabin Embarked Title . 0 0 | 3 | 0 | 22.0 | 1 | 0 | A/5 21171 | 7.2500 | NaN | S | 1 | . 1 1 | 1 | 1 | 38.0 | 1 | 0 | PC 17599 | 71.2833 | C85 | C | 3 | . 2 1 | 3 | 1 | 26.0 | 0 | 0 | STON/O2. 3101282 | 7.9250 | NaN | S | 2 | . 3 1 | 1 | 1 | 35.0 | 1 | 0 | 113803 | 53.1000 | C123 | S | 3 | . 4 0 | 3 | 0 | 35.0 | 0 | 0 | 373450 | 8.0500 | NaN | S | 1 | . grid = sns.FacetGrid(train, row=&#39;Pclass&#39;, col=&#39;Sex&#39;, size=5) grid.map(plt.hist, &#39;Age&#39;, alpha=.5, bins=20) grid.add_legend() . /home/jithin/.local/lib/python3.8/site-packages/seaborn/axisgrid.py:316: UserWarning: The `size` parameter has been renamed to `height`; please update your code. warnings.warn(msg, UserWarning) . &lt;seaborn.axisgrid.FacetGrid at 0x7f4706753550&gt; . for dataset in df: dataset[&quot;Age&quot;].fillna(dataset.groupby(&quot;Title&quot;)[&quot;Age&quot;].transform(&quot;median&quot;), inplace=True) train.isnull().sum() . Survived 0 Pclass 0 Sex 0 Age 0 SibSp 0 Parch 0 Ticket 0 Fare 0 Cabin 687 Embarked 2 Title 0 dtype: int64 . train[&#39;AgeBand&#39;] = pd.cut(train[&#39;Age&#39;], 5) train[[&#39;AgeBand&#39;, &#39;Survived&#39;]].groupby([&#39;AgeBand&#39;],as_index=False).mean().sort_values(by=&#39;AgeBand&#39;, ascending=True) . AgeBand Survived . 0 (0.34, 16.336] | 0.548077 | . 1 (16.336, 32.252] | 0.327345 | . 2 (32.252, 48.168] | 0.439024 | . 3 (48.168, 64.084] | 0.428571 | . 4 (64.084, 80.0] | 0.090909 | . Age values should be replaced as ordinals. . for dataset in df: dataset.loc[ dataset[&#39;Age&#39;] &lt;= 16, &#39;Age&#39;] = 0 dataset.loc[(dataset[&#39;Age&#39;] &gt; 16) &amp; (dataset[&#39;Age&#39;] &lt;= 32), &#39;Age&#39;] = 1 dataset.loc[(dataset[&#39;Age&#39;] &gt; 32) &amp; (dataset[&#39;Age&#39;] &lt;= 48), &#39;Age&#39;] = 2 dataset.loc[(dataset[&#39;Age&#39;] &gt; 48) &amp; (dataset[&#39;Age&#39;] &lt;= 64), &#39;Age&#39;] = 3 dataset.loc[ dataset[&#39;Age&#39;] &gt; 64, &#39;Age&#39;] train.head() . Survived Pclass Sex Age SibSp Parch Ticket Fare Cabin Embarked Title AgeBand . 0 0 | 3 | 0 | 1.0 | 1 | 0 | A/5 21171 | 7.2500 | NaN | S | 1 | (16.336, 32.252] | . 1 1 | 1 | 1 | 2.0 | 1 | 0 | PC 17599 | 71.2833 | C85 | C | 3 | (32.252, 48.168] | . 2 1 | 3 | 1 | 1.0 | 0 | 0 | STON/O2. 3101282 | 7.9250 | NaN | S | 2 | (16.336, 32.252] | . 3 1 | 1 | 1 | 2.0 | 1 | 0 | 113803 | 53.1000 | C123 | S | 3 | (32.252, 48.168] | . 4 0 | 3 | 0 | 2.0 | 0 | 0 | 373450 | 8.0500 | NaN | S | 1 | (32.252, 48.168] | . train = train.drop([&#39;AgeBand&#39;], axis=1) #removing AgeBand df = [train, test] train.head() . Survived Pclass Sex Age SibSp Parch Ticket Fare Cabin Embarked Title . 0 0 | 3 | 0 | 1.0 | 1 | 0 | A/5 21171 | 7.2500 | NaN | S | 1 | . 1 1 | 1 | 1 | 2.0 | 1 | 0 | PC 17599 | 71.2833 | C85 | C | 3 | . 2 1 | 3 | 1 | 1.0 | 0 | 0 | STON/O2. 3101282 | 7.9250 | NaN | S | 2 | . 3 1 | 1 | 1 | 2.0 | 1 | 0 | 113803 | 53.1000 | C123 | S | 3 | . 4 0 | 3 | 0 | 2.0 | 0 | 0 | 373450 | 8.0500 | NaN | S | 1 | . for dataset in df: dataset[&#39;FamilySize&#39;] = dataset[&#39;SibSp&#39;] + dataset[&#39;Parch&#39;] + 1 train[[&#39;FamilySize&#39;, &#39;Survived&#39;]].groupby([&#39;FamilySize&#39;], as_index=False).mean().sort_values(by=&#39;Survived&#39;, ascending=False) . FamilySize Survived . 3 4 | 0.724138 | . 2 3 | 0.578431 | . 1 2 | 0.552795 | . 6 7 | 0.333333 | . 0 1 | 0.303538 | . 4 5 | 0.200000 | . 5 6 | 0.136364 | . 7 8 | 0.000000 | . 8 11 | 0.000000 | . for dataset in df: dataset[&#39;Alone&#39;] = 0 dataset.loc[dataset[&#39;FamilySize&#39;] == 1, &#39;Alone&#39;] = 1 train[[&#39;Alone&#39;, &#39;Survived&#39;]].groupby([&#39;Alone&#39;], as_index=False).mean() . Alone Survived . 0 0 | 0.505650 | . 1 1 | 0.303538 | . train = train.drop([&#39;Parch&#39;, &#39;SibSp&#39;, &#39;FamilySize&#39;,&#39;Ticket&#39;,&#39;Cabin&#39;], axis=1) test = test.drop([&#39;Parch&#39;, &#39;SibSp&#39;, &#39;FamilySize&#39;,&#39;Ticket&#39;,&#39;Cabin&#39;], axis=1) df = [train, test] train.head() . Survived Pclass Sex Age Fare Embarked Title Alone . 0 0 | 3 | 0 | 1.0 | 7.2500 | S | 1 | 0 | . 1 1 | 1 | 1 | 2.0 | 71.2833 | C | 3 | 0 | . 2 1 | 3 | 1 | 1.0 | 7.9250 | S | 2 | 1 | . 3 1 | 1 | 1 | 2.0 | 53.1000 | S | 3 | 0 | . 4 0 | 3 | 0 | 2.0 | 8.0500 | S | 1 | 1 | . train.isnull().sum() . Survived 0 Pclass 0 Sex 0 Age 0 Fare 0 Embarked 2 Title 0 Alone 0 dtype: int64 . mode = train.Embarked.dropna().mode()[0] for dataset in df: dataset[&#39;Embarked&#39;] = dataset[&#39;Embarked&#39;].fillna(mode) train[[&#39;Embarked&#39;, &#39;Survived&#39;]].groupby([&#39;Embarked&#39;], as_index=False).mean().sort_values(by=&#39;Survived&#39;, ascending=False) . Embarked Survived . 0 C | 0.553571 | . 1 Q | 0.389610 | . 2 S | 0.339009 | . Converting categorical values to numeric values . for dataset in df: dataset[&#39;Embarked&#39;] = dataset[&#39;Embarked&#39;].map( {&#39;S&#39;: 0, &#39;C&#39;: 1, &#39;Q&#39;: 2} ).astype(int) train.head() . Survived Pclass Sex Age Fare Embarked Title Alone . 0 0 | 3 | 0 | 1.0 | 7.2500 | 0 | 1 | 0 | . 1 1 | 1 | 1 | 2.0 | 71.2833 | 1 | 3 | 0 | . 2 1 | 3 | 1 | 1.0 | 7.9250 | 0 | 2 | 1 | . 3 1 | 1 | 1 | 2.0 | 53.1000 | 0 | 3 | 0 | . 4 0 | 3 | 0 | 2.0 | 8.0500 | 0 | 1 | 1 | . train.isnull().sum() . Survived 0 Pclass 0 Sex 0 Age 0 Fare 0 Embarked 0 Title 0 Alone 0 dtype: int64 . test.isnull().sum() . PassengerId 0 Pclass 0 Sex 0 Age 0 Fare 1 Embarked 0 Title 0 Alone 0 dtype: int64 . test[&#39;Fare&#39;].fillna(test[&#39;Fare&#39;].dropna().median(), inplace=True) test.head() . PassengerId Pclass Sex Age Fare Embarked Title Alone . 0 892 | 3 | 0 | 2.0 | 7.8292 | 2 | 1 | 1 | . 1 893 | 3 | 1 | 2.0 | 7.0000 | 0 | 3 | 0 | . 2 894 | 2 | 0 | 3.0 | 9.6875 | 2 | 1 | 1 | . 3 895 | 3 | 0 | 1.0 | 8.6625 | 0 | 1 | 1 | . 4 896 | 3 | 1 | 1.0 | 12.2875 | 0 | 3 | 0 | . train[&#39;FareBand&#39;] = pd.qcut(train[&#39;Fare&#39;], 4) train[[&#39;FareBand&#39;, &#39;Survived&#39;]].groupby([&#39;FareBand&#39;], as_index=False).mean().sort_values(by=&#39;FareBand&#39;, ascending=True) . FareBand Survived . 0 (-0.001, 7.91] | 0.197309 | . 1 (7.91, 14.454] | 0.303571 | . 2 (14.454, 31.0] | 0.454955 | . 3 (31.0, 512.329] | 0.581081 | . for dataset in df: dataset.loc[ dataset[&#39;Fare&#39;] &lt;= 7.91, &#39;Fare&#39;] = 0 dataset.loc[(dataset[&#39;Fare&#39;] &gt; 7.91) &amp; (dataset[&#39;Fare&#39;] &lt;= 14.454), &#39;Fare&#39;] = 1 dataset.loc[(dataset[&#39;Fare&#39;] &gt; 14.454) &amp; (dataset[&#39;Fare&#39;] &lt;= 31), &#39;Fare&#39;] = 2 dataset.loc[ dataset[&#39;Fare&#39;] &gt; 31, &#39;Fare&#39;] = 3 dataset[&#39;Fare&#39;] = dataset[&#39;Fare&#39;].astype(int) train = train.drop([&#39;FareBand&#39;], axis=1) df = [train, test] train.head() . Survived Pclass Sex Age Fare Embarked Title Alone . 0 0 | 3 | 0 | 1.0 | 0 | 0 | 1 | 0 | . 1 1 | 1 | 1 | 2.0 | 3 | 1 | 3 | 0 | . 2 1 | 3 | 1 | 1.0 | 1 | 0 | 2 | 1 | . 3 1 | 1 | 1 | 2.0 | 3 | 0 | 3 | 0 | . 4 0 | 3 | 0 | 2.0 | 1 | 0 | 1 | 1 | . test.head() . PassengerId Pclass Sex Age Fare Embarked Title Alone . 0 892 | 3 | 0 | 2.0 | 0 | 2 | 1 | 1 | . 1 893 | 3 | 1 | 2.0 | 0 | 0 | 3 | 0 | . 2 894 | 2 | 0 | 3.0 | 1 | 2 | 1 | 1 | . 3 895 | 3 | 0 | 1.0 | 1 | 0 | 1 | 1 | . 4 896 | 3 | 1 | 1.0 | 1 | 0 | 3 | 0 | . Modelling . Now we can train a model and predict the required solution.Best Model should be selected from these ML algorithms. . Logistic Regression | KNN or k-Nearest Neighbors | Support Vector Machines | Naive Bayes classifier | Decision Tree | Random Forrest | . X_train = train.drop(&quot;Survived&quot;, axis=1) Y_train = train[&quot;Survived&quot;] X_test = test.drop(&quot;PassengerId&quot;, axis=1).copy() X_train.shape, Y_train.shape, X_test.shape . ((891, 7), (891,), (418, 7)) . logreg = LogisticRegression() logreg.fit(X_train, Y_train) Y_pred = logreg.predict(X_test) acc_log = round(logreg.score(X_train, Y_train) * 100, 2) acc_log . 78.56 . coeff_df = pd.DataFrame(train.columns.delete(0)) coeff_df.columns = [&#39;Feature&#39;] coeff_df[&quot;Correlation&quot;] = pd.Series(logreg.coef_[0]) coeff_df.sort_values(by=&#39;Correlation&#39;, ascending=False) . Feature Correlation . 1 Sex | 2.148684 | . 5 Title | 0.413368 | . 4 Embarked | 0.313126 | . 6 Alone | 0.051407 | . 2 Age | -0.032112 | . 3 Fare | -0.037693 | . 0 Pclass | -0.996006 | . svc = SVC() svc.fit(X_train, Y_train) Y_pred = svc.predict(X_test) acc_svc = round(svc.score(X_train, Y_train) * 100, 2) acc_svc . 78.34 . knn = KNeighborsClassifier(n_neighbors = 3) knn.fit(X_train, Y_train) Y_pred = knn.predict(X_test) acc_knn = round(knn.score(X_train, Y_train) * 100, 2) acc_knn . 83.84 . gaussian = GaussianNB() gaussian.fit(X_train, Y_train) Y_pred = gaussian.predict(X_test) acc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2) acc_gaussian . 76.99 . decision_tree = DecisionTreeClassifier() decision_tree.fit(X_train, Y_train) Y_pred = decision_tree.predict(X_test) acc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2) acc_decision_tree . 87.21 . random_forest = RandomForestClassifier(n_estimators=100) random_forest.fit(X_train, Y_train) Y_pred = random_forest.predict(X_test) random_forest.score(X_train, Y_train) acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2) acc_random_forest . 87.21 . models = pd.DataFrame({ &#39;Model&#39;: [&#39;Support Vector Machines&#39;, &#39;KNN&#39;, &#39;Logistic Regression&#39;, &#39;Random Forest&#39;,&#39;Naive Bayes&#39;,&#39;Decision Tree&#39;], &#39;Score&#39;: [acc_svc, acc_knn, acc_log, acc_random_forest, acc_gaussian, acc_decision_tree]}) models.sort_values(by=&#39;Score&#39;, ascending=False) . Model Score . 3 Random Forest | 87.21 | . 5 Decision Tree | 87.21 | . 1 KNN | 83.84 | . 2 Logistic Regression | 78.56 | . 0 Support Vector Machines | 78.34 | . 4 Naive Bayes | 76.99 | . submission = pd.DataFrame({ &quot;PassengerId&quot;: test[&quot;PassengerId&quot;], &quot;Survived&quot;: Y_pred }) . Any suggestions to improve our score are most welcome. . . twitter: https://twitter.com/jithinharidaas/ .",
            "url": "https://jithinharidas.github.io/paranormal-distributions/2021/04/21/Exploring-Titanic-Dataset.html",
            "relUrl": "/2021/04/21/Exploring-Titanic-Dataset.html",
            "date": " • Apr 21, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Jithin K Haridas . . I specialise in Advanced Analytics, a combination of exploratory data analysis, prescriptive and predictive analytics leveraging techniques across areas like statistical modelling, data mining, machine learning, text analytics. . .",
          "url": "https://jithinharidas.github.io/paranormal-distributions/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://jithinharidas.github.io/paranormal-distributions/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}